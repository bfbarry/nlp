{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return s.lower().split()\n",
    "\n",
    "text_corpus = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "[amount of training data](https://stackoverflow.com/questions/48059145/how-much-data-is-actually-required-to-train-a-doc2vec-model)\n",
    "\n",
    "# [Core Concepts](https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html)\n",
    "## preprocessed corpus: *filtering by stopwords and token frequencies*\n",
    "- this is a bit simplistic\n",
    "\n",
    "also see [`simple_preprocess()`](https://radimrehurek.com/gensim/utils.html#gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist = set('for a of the and to in'.split(' '))\n",
    "# remove stopwords\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] \n",
    "             for document in text_corpus]\n",
    "\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "clean_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "clean_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gensim dictionary\n",
    "[Construct word<->id mappings](https://radimrehurek.com/gensim/corpora/dictionary.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-07T02:51:18.370339Z",
     "iopub.status.busy": "2021-10-07T02:51:18.369776Z",
     "iopub.status.idle": "2021-10-07T02:51:22.254109Z",
     "shell.execute_reply": "2021-10-07T02:51:22.252492Z",
     "shell.execute_reply.started": "2021-10-07T02:51:18.370272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(clean_corpus)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforming new docs\n",
    "Has to be tokenized first!\n",
    "\n",
    "`(token_id, token_count)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-07T02:51:22.257690Z",
     "iopub.status.busy": "2021-10-07T02:51:22.257071Z",
     "iopub.status.idle": "2021-10-07T02:51:22.266457Z",
     "shell.execute_reply": "2021-10-07T02:51:22.264711Z",
     "shell.execute_reply.started": "2021-10-07T02:51:22.257627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(tokenize(new_doc))  \n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  vectorize Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-07T02:52:24.541856Z",
     "iopub.status.busy": "2021-10-07T02:52:24.541350Z",
     "iopub.status.idle": "2021-10-07T02:52:24.578633Z",
     "shell.execute_reply": "2021-10-07T02:52:24.576715Z",
     "shell.execute_reply.started": "2021-10-07T02:52:24.541785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
       " [(1, 1), (5, 2), (8, 1)],\n",
       " [(3, 1), (6, 1), (7, 1)],\n",
       " [(9, 1)],\n",
       " [(9, 1), (10, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(4, 1), (10, 1), (11, 1)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(toks) for toks in clean_corpus]\n",
    "bow_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "\"The tf-idf model transforms vectors from the bag-of-words representation to a vector space where the frequency counts are weighted according to the relative rarity of each word in the corpus.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-07T02:51:22.315297Z",
     "iopub.status.busy": "2021-10-07T02:51:22.314764Z",
     "iopub.status.idle": "2021-10-07T02:51:22.339964Z",
     "shell.execute_reply": "2021-10-07T02:51:22.336471Z",
     "shell.execute_reply.started": "2021-10-07T02:51:22.315230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 0.5898341626740045), (11, 0.8075244024440723)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus) # this fits it\n",
    "\n",
    "sample_words = tokenize(\"system minors\")\n",
    "print(tfidf[dictionary.doc2bow(sample_words)]) # model is like a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Corpora and Vector Spaces](https://radimrehurek.com/gensim/auto_examples/core/run_corpora_and_vector_spaces.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(texts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
